{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END_Assignment4_SentimentAnalysisUsingPytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olakf7vu2eVY"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqiIKOM57BHl"
      },
      "source": [
        "Reference [Notebook](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb)\n",
        "\n",
        "Implementation changes from above Notebook\n",
        "1. 3 seperate LSTM layers\n",
        "2. Used a for loop to do so in the forward function\n",
        "3. Trained on the text that is reversed (for example \"my name is Rohan\" becomes \"Rohan is name my\")\n",
        "4. Achieves 87% or more accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHL3-VrU2tzX"
      },
      "source": [
        "Build a machine learning model to detect sentiment (i.e. detect if a sentence is positive or negative) using PyTorch and TorchText. This will be done on movie reviews, using the IMDb dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHtoO8tw6JbB"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBGdjES526b1"
      },
      "source": [
        "The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as torchtext.datasets objects. It process the data using the Fields we have previously defined. The IMDb dataset consists of 50,000 movie reviews, each marked as being a positive or negative review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mt1GO5U6kIg"
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUmqbRtb3DA9"
      },
      "source": [
        "Sample review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkAk6q35ldvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f789212-dd4c-45ba-87ac-fb3ee2c0dfc7"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['A', 'great', 'storyline', 'with', 'a', 'message', '.', 'Joan', 'Plowright', 'is', 'superb', 'as', '\"', 'Phoebe', '\"', ',', 'Mike', 'Kopsa', 'is', 'hilarious', 'as', '\"', 'coach', '\"', 'and', 'Richard', 'de', 'Klerk', 'plays', 'the', 'role', 'of', '\"', 'Carmine', '\"', 'superbly', '.', 'Mischa', 'Barton', 'as', '\"', 'Frankie', '\"', 'puts', 'in', 'a', 'good', 'performance', 'and', 'Ingrid', 'as', '\"', 'Hazel', '\"', 'plays', 'her', 'first', 'lead', 'extremely', 'well', '.', 'This', 'film', 'is', 'superbly', 'directed', 'by', 'Jo', '-', 'Beth', 'Williams', '.', 'The', 'editing', 'is', 'first', 'rate', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E3Mh__K3IDF"
      },
      "source": [
        "Reverse the text in Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQTHd3nClfXW"
      },
      "source": [
        "for i in range(len(train_data)):\n",
        "  train_data.examples[i].text = train_data.examples[i].text[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja9BtjMm3NiV"
      },
      "source": [
        "Same reversed sample review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5VH9QYlpQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa9e19b-ad2d-4e62-edff-0a9c2cb29c04"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['.', 'rate', 'first', 'is', 'editing', 'The', '.', 'Williams', 'Beth', '-', 'Jo', 'by', 'directed', 'superbly', 'is', 'film', 'This', '.', 'well', 'extremely', 'lead', 'first', 'her', 'plays', '\"', 'Hazel', '\"', 'as', 'Ingrid', 'and', 'performance', 'good', 'a', 'in', 'puts', '\"', 'Frankie', '\"', 'as', 'Barton', 'Mischa', '.', 'superbly', '\"', 'Carmine', '\"', 'of', 'role', 'the', 'plays', 'Klerk', 'de', 'Richard', 'and', '\"', 'coach', '\"', 'as', 'hilarious', 'is', 'Kopsa', 'Mike', ',', '\"', 'Phoebe', '\"', 'as', 'superb', 'is', 'Plowright', 'Joan', '.', 'message', 'a', 'with', 'storyline', 'great', 'A'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjGOpRly3Tu-"
      },
      "source": [
        "Create Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORsC0LkHm95w"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3dHEedmm_ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1084835e-f566-4e49-a660-65d20a7b1336"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rdyOsjS3Y_O"
      },
      "source": [
        "The following builds the vocabulary, only keeping the most common max_size tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReuiPBeG6G_t"
      },
      "source": [
        "Next is the use of pre-trained word embeddings. Now, instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors. We get these vectors simply by specifying which vectors we want and passing it as an argument to build_vocab. TorchText handles downloading the vectors and associating them with the correct words in our vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QipWSZJ6KFO"
      },
      "source": [
        "By default, TorchText will initialize words in your vocabulary but not in your pre-trained embeddings to zero. We don't want this, and instead initialize them randomly by setting unk_init to torch.Tensor.normal_. This will now initialize those words via a Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mjhXaUym_aK"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKGUU7dS3851"
      },
      "source": [
        "As before, we create the iterators, placing the tensors on the GPU if one is available.\n",
        "\n",
        "Another thing for packed padded sequences all of the tensors within a batch need to be sorted by their lengths. This is handled in the iterator by setting sort_within_batch = True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KplCUxq9nYai"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjN9Vhdh4Eh0"
      },
      "source": [
        "Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxOy0APz4GA3"
      },
      "source": [
        "Three seperate LSTM Layers\n",
        "\n",
        "For loop in the forward function to pass through each LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wKUspw9obtK"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.layers = nn.ModuleList() # Definition of Layers as ModuleList()\n",
        "        self.layers.append(nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)) # First layer is Embedding Layer\n",
        "        self.layers.append(nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=1)) # 1st LSTM layer\n",
        "\n",
        "        self.layers.append(nn.LSTM(hidden_dim, \n",
        "                    hidden_dim, \n",
        "                    num_layers=1)) # 2nd LSTM layer\n",
        "\n",
        "        self.layers.append(nn.LSTM(hidden_dim, \n",
        "            hidden_dim, \n",
        "            num_layers=1)) # 3rd LSTM layer\n",
        "\n",
        "        self.layers.append(nn.Linear(hidden_dim, output_dim)) # Linear Layer\n",
        "        self.layers.append(nn.Dropout(dropout)) # Dropout \n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.layers[-1](self.layers[0](text)) # Applying Dropout \n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        hidden = packed_embedded\n",
        "        for layer in range(1,(len(self.layers)-2)): # Iterate through three LSTM layers\n",
        "          # if layer != 1:\n",
        "          #   hidden =  self.layers[-1](hidden)\n",
        "          packed_output, (hidden, cell) = self.layers[layer](hidden) # Forward pass through three LSTM layers\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        hidden = self.layers[-1](hidden) # Applying Dropout \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.layers[-2](hidden) # Applying Linear function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kdbw3W859aV"
      },
      "source": [
        "To ensure the pre-trained vectors can be loaded into the model, the EMBEDDING_DIM must be equal to that of the pre-trained GloVe vectors loaded earlier.\n",
        "\n",
        "We get our pad token index from the vocabulary, getting the actual string representing the pad token from the field's pad_token attribute, which is <pad> by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPSLzLBnAJU7"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 64\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 3\n",
        "BIDIRECTIONAL = False\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB858kiYAPkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad93a9ab-e53d-484a-ddc8-27c295b47d28"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,609,321 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q56TKP7iAacf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abd69d5-254b-40d4-820c-e5d1dabc77b1"
      },
      "source": [
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-ubU3N26VIO"
      },
      "source": [
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZddE4DvAb25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca60506-48d6-452b-ea99-bb8fb2459fb3"
      },
      "source": [
        "model.layers[0].weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.9597,  0.8905, -0.7076,  ...,  0.3940, -1.2075, -0.9683],\n",
              "        [-0.3404,  0.2269,  0.0731,  ..., -0.4427,  0.6267,  0.2811],\n",
              "        [ 0.7507, -1.9179,  2.2029,  ..., -1.5966,  0.8308, -0.1398]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 589
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll--pJM26rRV"
      },
      "source": [
        "As our unk and pad token aren't in the pre-trained vocabulary they have been initialized using unk_init (an $\\mathcal{N}(0,1)$ distribution) when building our vocab. It is preferable to initialize them both to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment.\n",
        "\n",
        "We do this by manually setting their row in the embedding weights matrix to zeros. We get their row by finding the index of the tokens, which we have already done for the padding index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLaGJCblAdct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316a61c3-d173-4abd-dda8-440af44ab254"
      },
      "source": [
        "\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.layers[0].weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.layers[0].weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.layers[0].weight.data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.9597,  0.8905, -0.7076,  ...,  0.3940, -1.2075, -0.9683],\n",
            "        [-0.3404,  0.2269,  0.0731,  ..., -0.4427,  0.6267,  0.2811],\n",
            "        [ 0.7507, -1.9179,  2.2029,  ..., -1.5966,  0.8308, -0.1398]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlo5vXSe80LN"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fi6AjHp89Ud"
      },
      "source": [
        "We use ADAM optimizer and BCEWithLogitsLoss as it is a binary classification problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWn5L6XAAjZq"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5D2W9SLAujW"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkiuUs0l9IN1"
      },
      "source": [
        "Function to calculate accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw5w0lbzAzn2"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMYHZrWM9WGV"
      },
      "source": [
        "Function for training our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrYKVrrzA1P-"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        text_lengths = text_lengths.cpu()\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(0)\n",
        "\n",
        "        batch.label = batch.label.unsqueeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwB94oaX97B8"
      },
      "source": [
        "Function to evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4B0mqsuA3n3"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            text_lengths = text_lengths.cpu()\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(0)\n",
        "            batch.label = batch.label.unsqueeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir7rUDZ0A5Zt"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rgsWGo79_Tc"
      },
      "source": [
        "Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WtiGIsfA6ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948ef076-4387-45e0-e3ef-5747ddf9e59c"
      },
      "source": [
        "N_EPOCHS = 9\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.691 | Train Acc: 52.48%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 50.79%\n",
            "Epoch: 02 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.676 | Train Acc: 56.16%\n",
            "\t Val. Loss: 0.588 |  Val. Acc: 71.63%\n",
            "Epoch: 03 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.492 | Train Acc: 77.93%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 85.46%\n",
            "Epoch: 04 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.345 | Train Acc: 86.39%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 87.94%\n",
            "Epoch: 05 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.287 | Train Acc: 88.76%\n",
            "\t Val. Loss: 0.282 |  Val. Acc: 88.71%\n",
            "Epoch: 06 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.249 | Train Acc: 90.66%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 89.43%\n",
            "Epoch: 07 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.224 | Train Acc: 91.66%\n",
            "\t Val. Loss: 0.291 |  Val. Acc: 89.32%\n",
            "Epoch: 08 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.196 | Train Acc: 92.87%\n",
            "\t Val. Loss: 0.269 |  Val. Acc: 89.65%\n",
            "Epoch: 09 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.176 | Train Acc: 93.56%\n",
            "\t Val. Loss: 0.280 |  Val. Acc: 89.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc6GJtvW-C5F"
      },
      "source": [
        "Check Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GY8c-LgA-Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5243879d-3e22-417f-8d77-6524dfef4e92"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.315 | Test Acc: 87.17%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}